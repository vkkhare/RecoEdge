# FL Simulation

For the simulator both the aggregator and trainer are defined as a worker. Each worker has an assigned role that determines the kind of computation it will perform. 

It is the role of orchestrator to define these roles for the workers and initialize them.

For the purposes of the simulator the [train_fl](../train_fl.py) file behaves as the orchestrator and inititates all the workers.

# Federated Worker
The federated worker class implements all the networking and FL logic.

The developer needs to implement three basic methods of the federated worker- aggregation logic, client selection, and role description. 


## Worker Roles
Roles define the kind of computation each worker does.

In this tutorial, we are using the [FedAvg McMahan et al](https://arxiv.org/abs/1602.05629) strategy with random client selection. There are only two roles here namely, the aggregator and trainer.

- **Aggregator** requests models from the trainers before aggregating and updating its model.
- **Trainer** responds to aggregators' requests after updating its own model by local training.

We define these roles in the `run()` method of Federated Worker.

```python

@registry.load('fl_algo', 'fed_avg')
class FedAvgWorker(FederatedWorker):
    def __init__(self, ...):
        super().__init__(...)

    async def run(self):
        assert role in self.roles, InvalidStateError("unknown role for worker")

        if role == 'aggregator':
            # central server in this case
            neighbours = await self.request_models_suspendable(self.sample_neighbours())
            weighted_params = self.aggregate(neighbours)
            self.update_model(weighted_params)
        elif role == 'trainer':
            aggregators = list(self.out_neighbours.values())
            global_models = await self.request_models_suspendable(aggregators)
            self.update_model(global_models[0])
            await self.train(model_dir=self.persistent_storage)
        self.round_idx += 1
```

## Aggregation Strategy

Aggregation strategy defines how the model updates from trainers will be combined into a single model update. Every FL paper proposes different Fl strategies for personalization, parallelization, accuracy improvement, etc.

The most recent ones propose a second order aggregation strategy to accomodate losses in the communication. We here would be running the simplest one - average them all!

```python
    # Your aggregation strategy
    def aggregate(self, neighbour_ids):
        model_list = [
            (self.in_neighbours[id].sample_num, self.in_neighbours[id].model)
            for id in neighbour_ids
        ]
        (num0, averaged_params) = model_list[0]
        for k in averaged_params.keys():
            for i in range(0, len(model_list)):
                local_sample_number, local_model_params = model_list[i]
                w = local_sample_number / training_num
                if i == 0:
                    averaged_params[k] = local_model_params[k] * w
                else:
                    averaged_params[k] += local_model_params[k] * w

        return averaged_params
```

## Client Selection
This is one of the most crucial stages of FL cycle. It is necessary to build a robust client selection strategy. It can save you from mallicious poisoning attacks, biased models and slow training cycles.

NimbleEdge brings along specific algorithms that augments the client selection strategy to deal with the above problems.

For now we just take random selection...

```python
    # Your sampling strategy
    def sample_neighbours(self, round_idx, client_num_per_round):
        num_neighbours = len(self.in_neighbours)
        if num_neighbours == client_num_per_round:
            selected_neighbours = [
                neighbour for neighbour in self.in_neighbours]
        else:
            with RandomContext(round_idx):
                selected_neighbours = np.random.choice(
                    self.in_neighbours, min(client_num_per_round, num_neighbours), replace=False)
        logging.info("worker_indexes = %s" % str(selected_neighbours))
        return selected_neighbours
```

# Hurray!
And it's done. Simply run the [train_fl.py](../train_fl.py) and see the simulator in action.